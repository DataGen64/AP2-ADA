{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIT5149 - Applied Data Analysis - Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize    \n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, matthews_corrcoef\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB,BernoulliNB\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xml.etree.ElementTree as ET\n",
    "from sklearn import preprocessing\n",
    "import re, string\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>d7d392835f50664fc079f0f388e147a0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ee40b86368137b86f51806c9f105b34b</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>919bc742d9a22d65eab1f52b11656cab</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>15b97a08d65f22d97ca685686510b6ae</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>affa98421ef5c46ca7c8f246e0a134c1</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3095</td>\n",
       "      <td>97159e619b8d88bdd837f7f7e738de43</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3096</td>\n",
       "      <td>9bccadb3d0033a2b2ad4403184ea72f5</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3097</td>\n",
       "      <td>f252cb406d4c27e71414148175fe6878</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3098</td>\n",
       "      <td>5dcf483c6ceb4cdf9de1648486f28706</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3099</td>\n",
       "      <td>5e877ae08d481609c0a828aaa2ba9bb0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  gender  label\n",
       "0     d7d392835f50664fc079f0f388e147a0    male      1\n",
       "1     ee40b86368137b86f51806c9f105b34b  female      0\n",
       "2     919bc742d9a22d65eab1f52b11656cab    male      1\n",
       "3     15b97a08d65f22d97ca685686510b6ae  female      0\n",
       "4     affa98421ef5c46ca7c8f246e0a134c1  female      0\n",
       "...                                ...     ...    ...\n",
       "3095  97159e619b8d88bdd837f7f7e738de43    male      1\n",
       "3096  9bccadb3d0033a2b2ad4403184ea72f5  female      0\n",
       "3097  f252cb406d4c27e71414148175fe6878  female      0\n",
       "3098  5dcf483c6ceb4cdf9de1648486f28706  female      0\n",
       "3099  5e877ae08d481609c0a828aaa2ba9bb0    male      1\n",
       "\n",
       "[3100 rows x 3 columns]"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Encode Labels\n",
    "le = preprocessing.LabelEncoder()\n",
    "train_labels['label'] = le.fit_transform(train_labels.gender.values)\n",
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_training_docs(data):\n",
    "    train_data = data\n",
    "    for index, row in train_labels.iterrows():\n",
    "        doc_string = \"\"\n",
    "        tree = ET.parse('data/'+row['id']+'.xml')\n",
    "        document = tree.getroot().find(\"documents\").findall(\"document\")\n",
    "        for doc in document:\n",
    "            doc_string = doc_string + \" \" + doc.text\n",
    "        train_labels.loc[index,'document'] = doc_string\n",
    "    return train_data\n",
    "\n",
    "train_labels = parse_training_docs(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data = train_test_split(train_labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>gender</th>\n",
       "      <th>label</th>\n",
       "      <th>document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1783</td>\n",
       "      <td>87483c7bbfb84744bed74199f986d9d0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>Fucking A!!! @cardiffdevils @FarmerG5 @SamDun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2577</td>\n",
       "      <td>ac196f715c1d41959ec006cb21966fc5</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>You don't feel like hiding in your personal c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>975</td>\n",
       "      <td>e83d63fb5c8acb7bc67e574b20fb484b</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>@AGhostler *if @AGhostler I would not recomme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3062</td>\n",
       "      <td>1890ce7f4ef5c16a89ba04eef28c7756</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "      <td>@realDonaldTrump pathetic leadership “Still, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>85b7b6367d73f9c7a5f4db51312020e4</td>\n",
       "      <td>female</td>\n",
       "      <td>0</td>\n",
       "      <td>@nypost by weighing they mean they have a spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    id  gender  label  \\\n",
       "1783  87483c7bbfb84744bed74199f986d9d0    male      1   \n",
       "2577  ac196f715c1d41959ec006cb21966fc5  female      0   \n",
       "975   e83d63fb5c8acb7bc67e574b20fb484b    male      1   \n",
       "3062  1890ce7f4ef5c16a89ba04eef28c7756    male      1   \n",
       "163   85b7b6367d73f9c7a5f4db51312020e4  female      0   \n",
       "\n",
       "                                               document  \n",
       "1783   Fucking A!!! @cardiffdevils @FarmerG5 @SamDun...  \n",
       "2577   You don't feel like hiding in your personal c...  \n",
       "975    @AGhostler *if @AGhostler I would not recomme...  \n",
       "3062   @realDonaldTrump pathetic leadership “Still, ...  \n",
       "163    @nypost by weighing they mean they have a spe...  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of Training documents are:  2480\n",
      "The number of Validation documents are:  620\n"
     ]
    }
   ],
   "source": [
    "print(\"The number of Training documents are: \", len(train_data))\n",
    "print(\"The number of Validation documents are: \", len(validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = train_data[\"document\"] .tolist()\n",
    "train_labels = train_data[\"label\"].tolist()\n",
    "\n",
    "validation_docs = validation_data[\"document\"] .tolist()\n",
    "validation_labels = validation_data[\"label\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, string\n",
    "def clean_documents(document):\n",
    "    # Remove square brackets characters\n",
    "#     document = re.sub(r'\\[.*?\\]', '', document)\n",
    "    #Remove URL\n",
    "    document = re.sub(r'http\\S+', '', document)\n",
    "    #Remove user mentions\n",
    "    document = re.sub(r\"@(\\w+)\", ' ', document, flags=re.MULTILINE)\n",
    "    #Remove punctuations\n",
    "    document = re.sub(r'[%s]' % re.escape(string.punctuation), '', document)\n",
    "    #Remove words with numbers\n",
    "    document = re.sub(r'\\w*\\d\\w*', '', document)  \n",
    "    #Remove triple dots\n",
    "    document = document.replace(\"…\", \" \")\n",
    "    #Remove Quotes\n",
    "    document = document.replace(\"'\", \"\")\n",
    "    document = document.replace(\"\\\"\", \"\")\n",
    "    document = document.replace(\"’\", \"\")\n",
    "    document = document.replace(\"“\", \"\")\n",
    "    document = document.replace(\"”\", \"\")\n",
    "    #convert to lowercase\n",
    "    document = document.lower()\n",
    "    return document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_docs = [clean_documents(doc) for doc in train_docs]\n",
    "validation_docs = [clean_documents(doc) for doc in validation_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize the documents\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer()\n",
    "train_docs = [tknzr.tokenize(doc) for doc in train_docs]\n",
    "validation_docs = [tknzr.tokenize(doc) for doc in validation_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lemmatize and Remove stop words\n",
    "stopwords_list = stopwords.words('english')\n",
    "wnl = WordNetLemmatizer()\n",
    "train_docs = [[ wnl.lemmatize(token) for token in doc if token not in stopwords_list and len(token) > 0] for doc in train_docs]\n",
    "\n",
    "validation_docs = [[ wnl.lemmatize(token) for token in doc if token not in stopwords_list and len(token) > 0] for doc in validation_docs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove empty words after lemmatize\n",
    "train_docs = [[ token for token in doc if len(token) > 0] for doc in train_docs]\n",
    "validation_docs = [[ token for token in doc if len(token) > 0] for doc in validation_docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    input='content',\n",
    "    token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
    "    min_df = 5,\n",
    "    tokenizer=dummy_fun,\n",
    "    preprocessor=dummy_fun) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=vectorizer.fit_transform(train_docs)\n",
    "y_train=np.asarray(train_labels)\n",
    "\n",
    "x_valid=vectorizer.transform(validation_docs)\n",
    "y_valid=np.asarray(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aa',\n",
       " 'aaa',\n",
       " 'aaaaand',\n",
       " 'aaaand',\n",
       " 'aaah',\n",
       " 'aaliyah',\n",
       " 'aampe',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandon',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abba',\n",
       " 'abbey',\n",
       " 'abbotsford',\n",
       " 'abbott',\n",
       " 'abbotts',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abducted',\n",
       " 'abduction',\n",
       " 'abdullah',\n",
       " 'abe',\n",
       " 'abel',\n",
       " 'aberdeen',\n",
       " 'abhorrent',\n",
       " 'abiding',\n",
       " 'abigail',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abnormal',\n",
       " 'aboard',\n",
       " 'abolish',\n",
       " 'abolished',\n",
       " 'abomination',\n",
       " 'aboot',\n",
       " 'aboriginal',\n",
       " 'aborted',\n",
       " 'abortion',\n",
       " 'abou',\n",
       " 'abound',\n",
       " 'abounds',\n",
       " 'abraham',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'abruptly',\n",
       " 'absence',\n",
       " 'absent',\n",
       " 'abso',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absorb',\n",
       " 'absorbed',\n",
       " 'abstract',\n",
       " 'absurd',\n",
       " 'absurdity',\n",
       " 'absurdly',\n",
       " 'abt',\n",
       " 'abu',\n",
       " 'abundance',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abuser',\n",
       " 'abusing',\n",
       " 'abusive',\n",
       " 'abysmal',\n",
       " 'abyss',\n",
       " 'ac',\n",
       " 'aca',\n",
       " 'academia',\n",
       " 'academic',\n",
       " 'academy',\n",
       " 'acc',\n",
       " 'acca',\n",
       " 'accelerate',\n",
       " 'accelerates',\n",
       " 'accelerating',\n",
       " 'accelerator',\n",
       " 'accent',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'acceptance',\n",
       " 'accepted',\n",
       " 'accepting',\n",
       " 'accepts',\n",
       " 'access',\n",
       " 'accessibility',\n",
       " 'accessible',\n",
       " 'accessing',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accolade',\n",
       " 'accommodate',\n",
       " 'accommodation',\n",
       " 'accompanied',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'accord',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'accordion',\n",
       " 'account',\n",
       " 'accountability',\n",
       " 'accountable',\n",
       " 'accountant',\n",
       " 'accounted',\n",
       " 'accounting',\n",
       " 'acct',\n",
       " 'accumulation',\n",
       " 'accumulator',\n",
       " 'accuracy',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accuse',\n",
       " 'accused',\n",
       " 'accuses',\n",
       " 'accusing',\n",
       " 'accustomed',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'achievable',\n",
       " 'achieve',\n",
       " 'achieved',\n",
       " 'achievement',\n",
       " 'achieves',\n",
       " 'achieving',\n",
       " 'achilles',\n",
       " 'aching',\n",
       " 'acid',\n",
       " 'ack',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledges',\n",
       " 'acknowledging',\n",
       " 'acknowledgment',\n",
       " 'acl',\n",
       " 'aclu',\n",
       " 'acne',\n",
       " 'acorn',\n",
       " 'acoustic',\n",
       " 'acquire',\n",
       " 'acquired',\n",
       " 'acquisition',\n",
       " 'acre',\n",
       " 'acronym',\n",
       " 'across',\n",
       " 'acrylic',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acti',\n",
       " 'actin',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actionable',\n",
       " 'activate',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activist',\n",
       " 'activity',\n",
       " 'acton',\n",
       " 'actor',\n",
       " 'actress',\n",
       " 'actu',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'acute',\n",
       " 'ad',\n",
       " 'adam',\n",
       " 'adani',\n",
       " 'adapt',\n",
       " 'adaptation',\n",
       " 'adapted',\n",
       " 'adapter',\n",
       " 'adapting',\n",
       " 'adaptive',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addiction',\n",
       " 'addictive',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'addon',\n",
       " 'addons',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adelaide',\n",
       " 'adele',\n",
       " 'adequate',\n",
       " 'adhd',\n",
       " 'adhere',\n",
       " 'adhering',\n",
       " 'adidas',\n",
       " 'adjacent',\n",
       " 'adjective',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjusting',\n",
       " 'adjustment',\n",
       " 'admin',\n",
       " 'administration',\n",
       " 'administrative',\n",
       " 'administrator',\n",
       " 'admins',\n",
       " 'admirable',\n",
       " 'admiration',\n",
       " 'admire',\n",
       " 'admired',\n",
       " 'admiring',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'adobe',\n",
       " 'adolescent',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adopting',\n",
       " 'adoption',\n",
       " 'adopts',\n",
       " 'adorable',\n",
       " 'adorbs',\n",
       " 'adore',\n",
       " 'adored',\n",
       " 'adrenaline',\n",
       " 'adrian',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adulting',\n",
       " 'adv',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancement',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advent',\n",
       " 'adventure',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'advert',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertiser',\n",
       " 'advertising',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'adviser',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advisory',\n",
       " 'advocacy',\n",
       " 'advocate',\n",
       " 'advocating',\n",
       " 'adwords',\n",
       " 'ae',\n",
       " 'aedt',\n",
       " 'aer',\n",
       " 'aerial',\n",
       " 'aeroplane',\n",
       " 'aesthetic',\n",
       " 'af',\n",
       " 'afaik',\n",
       " 'afar',\n",
       " 'afc',\n",
       " 'aff',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affecting',\n",
       " 'affection',\n",
       " 'affiliate',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affirmation',\n",
       " 'affleck',\n",
       " 'afflicted',\n",
       " 'afford',\n",
       " 'affordability',\n",
       " 'affordable',\n",
       " 'affront',\n",
       " 'afghan',\n",
       " 'afghanistan',\n",
       " 'aficionado',\n",
       " 'afl',\n",
       " 'afloat',\n",
       " 'aflwbluespies',\n",
       " 'afoot',\n",
       " 'afp',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'african',\n",
       " 'africanamerican',\n",
       " 'aft',\n",
       " 'aftermath',\n",
       " 'afternoon',\n",
       " 'aftershock',\n",
       " 'aftertaste',\n",
       " 'afterwards',\n",
       " 'ag',\n",
       " 'aga',\n",
       " 'agatha',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'ageing',\n",
       " 'agency',\n",
       " 'agenda',\n",
       " 'agent',\n",
       " 'aggression',\n",
       " 'aggressive',\n",
       " 'aggressively',\n",
       " 'agh',\n",
       " 'agile',\n",
       " 'agility',\n",
       " 'aging',\n",
       " 'agitator',\n",
       " 'agm',\n",
       " 'ago',\n",
       " 'agony',\n",
       " 'agree',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agricultural',\n",
       " 'agriculture',\n",
       " 'ah',\n",
       " 'aha',\n",
       " 'ahah',\n",
       " 'ahaha',\n",
       " 'ahahaha',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahern',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahhhhhh',\n",
       " 'ahl',\n",
       " 'ahmed',\n",
       " 'ai',\n",
       " 'aid',\n",
       " 'aidan',\n",
       " 'aide',\n",
       " 'aiding',\n",
       " 'aig',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimee',\n",
       " 'aiming',\n",
       " 'aint',\n",
       " 'air',\n",
       " 'airbnb',\n",
       " 'airborne',\n",
       " 'aircon',\n",
       " 'aircraft',\n",
       " 'aired',\n",
       " 'airing',\n",
       " 'airline',\n",
       " 'airnz',\n",
       " 'airplane',\n",
       " 'airpods',\n",
       " 'airport',\n",
       " 'airtime',\n",
       " 'airway',\n",
       " 'aisle',\n",
       " 'aj',\n",
       " 'ak',\n",
       " 'aka',\n",
       " 'akbar',\n",
       " 'akin',\n",
       " 'akl',\n",
       " 'ako',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'aladdin',\n",
       " 'alan',\n",
       " 'alana',\n",
       " 'alanis',\n",
       " 'alarm',\n",
       " 'alarmed',\n",
       " 'alarming',\n",
       " 'alarmist',\n",
       " 'alaska',\n",
       " 'albany',\n",
       " 'albeit',\n",
       " 'albert',\n",
       " 'alberta',\n",
       " 'alberto',\n",
       " 'album',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'aldi',\n",
       " 'aldo',\n",
       " 'ale',\n",
       " 'aleague',\n",
       " 'alec',\n",
       " 'aleppo',\n",
       " 'alert',\n",
       " 'alerted',\n",
       " 'alex',\n",
       " 'alexa',\n",
       " 'alexander',\n",
       " 'alexandra',\n",
       " 'alexandre',\n",
       " 'alexandria',\n",
       " 'alexis',\n",
       " 'alfred',\n",
       " 'algorithm',\n",
       " 'ali',\n",
       " 'alia',\n",
       " 'alibaba',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'alien',\n",
       " 'alienate',\n",
       " 'alienated',\n",
       " 'alienating',\n",
       " 'align',\n",
       " 'aligned',\n",
       " 'aligning',\n",
       " 'alignment',\n",
       " 'alike',\n",
       " 'alison',\n",
       " 'alist',\n",
       " 'alive',\n",
       " 'allah',\n",
       " 'allan',\n",
       " 'allblacks',\n",
       " 'allday',\n",
       " 'allegation',\n",
       " 'alleged',\n",
       " 'allegedly',\n",
       " 'allegiance',\n",
       " 'allen',\n",
       " 'allergic',\n",
       " 'allergy',\n",
       " 'alley',\n",
       " 'alli',\n",
       " 'alliance',\n",
       " 'allied',\n",
       " 'alligator',\n",
       " 'allison',\n",
       " 'alll',\n",
       " 'allll',\n",
       " 'allnew',\n",
       " 'allo',\n",
       " 'allocation',\n",
       " 'allow',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'alls',\n",
       " 'allstar',\n",
       " 'alltime',\n",
       " 'ally',\n",
       " 'alma',\n",
       " 'almanac',\n",
       " 'almighty',\n",
       " 'almond',\n",
       " 'almost',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'alpaca',\n",
       " 'alpha',\n",
       " 'alphabet',\n",
       " 'alphabetical',\n",
       " 'alpine',\n",
       " 'alqaeda',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alt',\n",
       " 'altar',\n",
       " 'alter',\n",
       " 'alternate',\n",
       " 'alternatefacts',\n",
       " 'alternative',\n",
       " 'alternativefact',\n",
       " 'alternativefacts',\n",
       " 'alternatively',\n",
       " 'alters',\n",
       " 'altfacts',\n",
       " 'altho',\n",
       " 'although',\n",
       " 'altitude',\n",
       " 'altogether',\n",
       " 'altright',\n",
       " 'alum',\n",
       " 'alumnus',\n",
       " 'always',\n",
       " 'aly',\n",
       " 'alzheimers',\n",
       " 'ama',\n",
       " 'amanda',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazon',\n",
       " 'amb',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambient',\n",
       " 'ambiguous',\n",
       " 'ambition',\n",
       " 'ambitious',\n",
       " 'ambivalent',\n",
       " 'ambrose',\n",
       " 'ambulance',\n",
       " 'amd',\n",
       " 'amen',\n",
       " 'amend',\n",
       " 'amended',\n",
       " 'amendment',\n",
       " 'amends',\n",
       " 'amenity',\n",
       " 'americ',\n",
       " 'america',\n",
       " 'americafirst',\n",
       " 'american',\n",
       " 'americano',\n",
       " 'amid',\n",
       " 'amidst',\n",
       " 'amigo',\n",
       " 'amiright',\n",
       " 'amirite',\n",
       " 'ammunition',\n",
       " 'amnesia',\n",
       " 'amnesty',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amoral',\n",
       " 'amount',\n",
       " 'amp',\n",
       " 'ampa',\n",
       " 'amped',\n",
       " 'ample',\n",
       " 'amplify',\n",
       " 'ampor',\n",
       " 'amreading',\n",
       " 'amsterdam',\n",
       " 'amt',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amwriting',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'ana',\n",
       " 'anagram',\n",
       " 'anaheim',\n",
       " 'anal',\n",
       " 'analog',\n",
       " 'analogue',\n",
       " 'analogy',\n",
       " 'analysis',\n",
       " 'analyst',\n",
       " 'analytics',\n",
       " 'analyzing',\n",
       " 'anarchist',\n",
       " 'anarchy',\n",
       " 'anatomy',\n",
       " 'anc',\n",
       " 'ancestor',\n",
       " 'ancestry',\n",
       " 'anchor',\n",
       " 'ancient',\n",
       " 'andersen',\n",
       " 'anderson',\n",
       " 'andor',\n",
       " 'andre',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'android',\n",
       " 'andy',\n",
       " 'andys',\n",
       " 'anecdotal',\n",
       " 'anecdote',\n",
       " 'anfield',\n",
       " 'ange',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelina',\n",
       " 'angelo',\n",
       " 'angelou',\n",
       " 'anger',\n",
       " 'angle',\n",
       " 'anglican',\n",
       " 'angrily',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'angsty',\n",
       " 'angus',\n",
       " 'animal',\n",
       " 'animated',\n",
       " 'animation',\n",
       " 'animator',\n",
       " 'anime',\n",
       " 'anita',\n",
       " 'ankle',\n",
       " 'ann',\n",
       " 'anna',\n",
       " 'anne',\n",
       " 'annette',\n",
       " 'annie',\n",
       " 'anniversary',\n",
       " 'annotated',\n",
       " 'announce',\n",
       " 'announced',\n",
       " 'announcement',\n",
       " 'announcer',\n",
       " 'announces',\n",
       " 'announcing',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annoys',\n",
       " 'annual',\n",
       " 'annually',\n",
       " 'anomaly',\n",
       " 'anon',\n",
       " 'anonymity',\n",
       " 'anonymous',\n",
       " 'anonymously',\n",
       " 'anot',\n",
       " 'another',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'ant',\n",
       " 'antarctic',\n",
       " 'antarctica',\n",
       " 'ante',\n",
       " 'antenna',\n",
       " 'anthem',\n",
       " 'anthology',\n",
       " 'anthony',\n",
       " 'anthrax',\n",
       " 'anthropology',\n",
       " 'anti',\n",
       " 'antiabortion',\n",
       " 'antibiotic',\n",
       " 'antic',\n",
       " 'antichoice',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'anticlimactic',\n",
       " 'antidote',\n",
       " 'antifa',\n",
       " 'antifascists',\n",
       " 'antigay',\n",
       " 'antiimmigration',\n",
       " 'antimuslim',\n",
       " 'antique',\n",
       " 'antiscience',\n",
       " 'antisemitic',\n",
       " 'antisemitism',\n",
       " 'antitrump',\n",
       " 'anton',\n",
       " 'antonio',\n",
       " 'antony',\n",
       " 'anu',\n",
       " 'anus',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anybody',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyones',\n",
       " 'anythi',\n",
       " 'anything',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anz',\n",
       " 'anzac',\n",
       " 'anzus',\n",
       " 'ao',\n",
       " 'aoife',\n",
       " 'aok',\n",
       " 'aotearoa',\n",
       " 'ap',\n",
       " 'apa',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartheid',\n",
       " 'apartment',\n",
       " 'apathy',\n",
       " 'ape',\n",
       " 'api',\n",
       " 'apis',\n",
       " 'apocalypse',\n",
       " 'apocalyptic',\n",
       " 'apolitical',\n",
       " 'apollo',\n",
       " 'apollohouse',\n",
       " 'apologise',\n",
       " 'apologised',\n",
       " 'apologising',\n",
       " 'apologist',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apostrophe',\n",
       " 'app',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparatus',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appeal',\n",
       " 'appealing',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appeared',\n",
       " 'appearing',\n",
       " 'appears',\n",
       " 'appease',\n",
       " 'appeasement',\n",
       " 'appeasing',\n",
       " 'appetite',\n",
       " 'applaud',\n",
       " 'applauding',\n",
       " 'applause',\n",
       " 'apple',\n",
       " 'appliance',\n",
       " 'applicable',\n",
       " 'applicant',\n",
       " 'application',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoint',\n",
       " 'appointed',\n",
       " 'appointee',\n",
       " 'appointment',\n",
       " 'appoints',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciating',\n",
       " 'appreciation',\n",
       " 'apprentice',\n",
       " 'apprenticeship',\n",
       " 'approach',\n",
       " 'approached',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriation',\n",
       " 'approval',\n",
       " 'approve',\n",
       " 'approved',\n",
       " 'approves',\n",
       " 'approx',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'apr',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apt',\n",
       " 'aptly',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquarius',\n",
       " 'ar',\n",
       " 'ara',\n",
       " 'arab',\n",
       " 'arabia',\n",
       " 'arabian',\n",
       " 'arabic',\n",
       " 'arbitrary',\n",
       " 'arc',\n",
       " 'arcade',\n",
       " 'arch',\n",
       " 'archaeological',\n",
       " 'archbishop',\n",
       " 'archer',\n",
       " 'archie',\n",
       " 'architect',\n",
       " 'architectural',\n",
       " 'architecture',\n",
       " 'archive',\n",
       " 'arctic',\n",
       " 'area',\n",
       " 'arena',\n",
       " 'arent',\n",
       " 'argentina',\n",
       " 'argh',\n",
       " 'arguably',\n",
       " 'argue',\n",
       " 'argued',\n",
       " 'argues',\n",
       " 'arguing',\n",
       " 'argument',\n",
       " 'aria',\n",
       " 'ariana',\n",
       " 'aries',\n",
       " 'arise',\n",
       " 'arizona',\n",
       " 'ark',\n",
       " 'arkansas',\n",
       " 'arlene',\n",
       " 'arlington',\n",
       " 'arm',\n",
       " 'armageddon',\n",
       " 'armed',\n",
       " 'armored',\n",
       " 'armour',\n",
       " 'armstrong',\n",
       " 'army',\n",
       " 'arnie',\n",
       " 'arnold',\n",
       " 'aro',\n",
       " 'aroha',\n",
       " 'around',\n",
       " 'arrange',\n",
       " 'arranged',\n",
       " 'arrangement',\n",
       " 'arranging',\n",
       " 'array',\n",
       " 'arrest',\n",
       " 'arrested',\n",
       " 'arrival',\n",
       " 'arrive',\n",
       " 'arrived',\n",
       " 'arrives',\n",
       " 'arriving',\n",
       " 'arrogance',\n",
       " 'arrogant',\n",
       " 'arrow',\n",
       " 'arse',\n",
       " 'arsed',\n",
       " 'arsehole',\n",
       " 'arsenal',\n",
       " 'arsene',\n",
       " 'art',\n",
       " 'arthur',\n",
       " 'article',\n",
       " 'articulate',\n",
       " 'articulated',\n",
       " 'artificial',\n",
       " 'artisan',\n",
       " 'artisanal',\n",
       " 'artist',\n",
       " 'artistic',\n",
       " 'artistry',\n",
       " 'artwork',\n",
       " 'arty',\n",
       " 'arvo',\n",
       " 'as',\n",
       " 'asap',\n",
       " 'asbestos',\n",
       " 'asda',\n",
       " 'asean',\n",
       " 'asexual',\n",
       " 'asf',\n",
       " 'ash',\n",
       " 'ashamed',\n",
       " 'asher',\n",
       " 'ashley',\n",
       " 'ashton',\n",
       " 'asia',\n",
       " 'asian',\n",
       " 'asiapacific',\n",
       " 'aside',\n",
       " 'asinine',\n",
       " 'ask',\n",
       " 'asked',\n",
       " 'asking',\n",
       " 'askingforafriend',\n",
       " 'asks',\n",
       " 'asleep',\n",
       " 'asos',\n",
       " 'asparagus',\n",
       " 'aspect',\n",
       " 'aspiration',\n",
       " 'aspirational',\n",
       " 'aspire',\n",
       " 'aspiring',\n",
       " 'ass',\n",
       " 'assad',\n",
       " 'assange',\n",
       " 'assassin',\n",
       " 'assassinated',\n",
       " 'assassination',\n",
       " 'assault',\n",
       " 'assaulted',\n",
       " 'assaulting',\n",
       " 'assemble',\n",
       " 'assembled',\n",
       " 'assembly',\n",
       " 'assert',\n",
       " 'asserting',\n",
       " 'assertion',\n",
       " 'asserts',\n",
       " 'assessed',\n",
       " 'assessing',\n",
       " 'assessment',\n",
       " 'asset',\n",
       " 'asshole',\n",
       " 'assign',\n",
       " 'assigned',\n",
       " 'assignment',\n",
       " 'assimilate',\n",
       " 'assist',\n",
       " 'assistance',\n",
       " 'assistant',\n",
       " 'assisted',\n",
       " 'assisting',\n",
       " 'associate',\n",
       " 'associated',\n",
       " 'associating',\n",
       " 'association',\n",
       " 'assume',\n",
       " 'assumed',\n",
       " 'assumes',\n",
       " 'assuming',\n",
       " 'assumption',\n",
       " 'assurance',\n",
       " 'assure',\n",
       " 'assured',\n",
       " 'asteroid',\n",
       " 'asthma',\n",
       " 'aston',\n",
       " 'astonished',\n",
       " 'astonishing',\n",
       " 'astounding',\n",
       " 'astray',\n",
       " 'astro',\n",
       " 'astronaut',\n",
       " 'astronomy',\n",
       " 'astute',\n",
       " 'aswell',\n",
       " 'asylum',\n",
       " 'ate',\n",
       " 'atheist',\n",
       " 'athens',\n",
       " 'athlete',\n",
       " 'athletic',\n",
       " 'athletics',\n",
       " 'athlone',\n",
       " 'atkinson',\n",
       " 'atl',\n",
       " 'atlanta',\n",
       " 'atlantic',\n",
       " 'atleast',\n",
       " 'atm',\n",
       " 'atmosphere',\n",
       " 'atmospheric',\n",
       " 'atom',\n",
       " 'atomic',\n",
       " 'atop',\n",
       " 'atrium',\n",
       " 'atrocious',\n",
       " 'atrocity',\n",
       " 'attach',\n",
       " 'attached',\n",
       " 'attachment',\n",
       " 'attack',\n",
       " 'attacked',\n",
       " 'attacker',\n",
       " 'attacking',\n",
       " ...]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>fold_idx</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0</td>\n",
       "      <td>0.826613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.850806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.798387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.754032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.822581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.794355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>6</td>\n",
       "      <td>0.806452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>7</td>\n",
       "      <td>0.818548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>8</td>\n",
       "      <td>0.802419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>9</td>\n",
       "      <td>0.754032</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name  fold_idx  accuracy\n",
       "0  LogisticRegression         0  0.826613\n",
       "1  LogisticRegression         1  0.850806\n",
       "2  LogisticRegression         2  0.798387\n",
       "3  LogisticRegression         3  0.754032\n",
       "4  LogisticRegression         4  0.822581\n",
       "5  LogisticRegression         5  0.794355\n",
       "6  LogisticRegression         6  0.806452\n",
       "7  LogisticRegression         7  0.818548\n",
       "8  LogisticRegression         8  0.802419\n",
       "9  LogisticRegression         9  0.754032"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_model = LogisticRegression()\n",
    "\n",
    "CV = 10\n",
    "cv_df = pd.DataFrame(index=range(CV * len(models)))\n",
    "entries = []\n",
    "\n",
    "model_name = logistic_regression_model.__class__.__name__\n",
    "accuracies = cross_val_score(logistic_regression_model, x_train, y_train, scoring='accuracy', cv=CV)\n",
    "for fold_idx, accuracy in enumerate(accuracies):\n",
    "    entries.append((model_name, fold_idx, accuracy))\n",
    "cv_df = pd.DataFrame(entries, columns=['model_name', 'fold_idx', 'accuracy'])\n",
    "\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "[[239  89]\n",
      " [ 57 235]]\n",
      "Accuracy: 0.7645161290322581\n",
      "Macro Precision: 0.7663705372038705\n",
      "Macro Recall: 0.7667265285666556\n",
      "Macro F1 score:0.764506327006327\n",
      "MCC:0.5330969469086221\n"
     ]
    }
   ],
   "source": [
    "#Measure performance on validation data\n",
    "logistic_regression_model.fit(x_train, y_train)\n",
    "print(model_name)\n",
    "# Do the prediction\n",
    "y_predict=logistic_regression_model.predict(x_valid)\n",
    "print(confusion_matrix(y_valid,y_predict))\n",
    "recall=recall_score(y_valid,y_predict,average='macro')\n",
    "precision=precision_score(y_valid,y_predict,average='macro')\n",
    "f1score=f1_score(y_valid,y_predict,average='macro')\n",
    "accuracy=accuracy_score(y_valid,y_predict)\n",
    "matthews = matthews_corrcoef(y_valid,y_predict) \n",
    "print('Accuracy: '+ str(accuracy))\n",
    "print('Macro Precision: '+ str(precision))\n",
    "print('Macro Recall: '+ str(recall))\n",
    "print('Macro F1 score:'+ str(f1score))\n",
    "print('MCC:'+ str(matthews))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
